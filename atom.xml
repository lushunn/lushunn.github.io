<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://lushunn.github.io</id>
    <title>hi~</title>
    <updated>2020-04-14T08:47:51.818Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://lushunn.github.io"/>
    <link rel="self" href="https://lushunn.github.io/atom.xml"/>
    <subtitle>凡有所相，皆为虚妄
</subtitle>
    <logo>https://lushunn.github.io/images/avatar.png</logo>
    <icon>https://lushunn.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, hi~</rights>
    <entry>
        <title type="html"><![CDATA[用PyTorch编写word2vec]]></title>
        <id>https://lushunn.github.io/post/yong-pytorch-bian-xie-word2vec</id>
        <link href="https://lushunn.github.io/post/yong-pytorch-bian-xie-word2vec">
        </link>
        <updated>2020-04-14T07:59:58.000Z</updated>
        <content type="html"><![CDATA[<p>参考资料 <a href="https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb/" title="Implementing word2vec in PyTorch (skip-gram model)">Implementing word2vec in PyTorch (skip-gram model)</a>.</p>
<h1 id="skip-gram-model">skip-gram model</h1>
<h2 id="1准备工作">1.准备工作</h2>
<p>假设我们有一下语料库：</p>
<pre><code class="language-python">corpus = [
    'he is a king',
    'she is a queen',
    'he is a man',
    'she is a woman',
    'warsaw is poland capital',
    'berlin is germany capital',
    'paris is france capital',
]
</code></pre>
<h2 id="2创建词汇表">2.创建词汇表</h2>
<p>对每条句子进行分词处理</p>
<pre><code class="language-python">def tokenize_corpus(corpus):
   tokens = [x.split() for x in corpus]
   return tokens

tokenized_corpus = tokenize_corpus(corpus)
</code></pre>
<p>得到结果为</p>
<blockquote>
<p>[['he', 'is', 'a', 'king'],<br>
['she', 'is', 'a', 'queen'],<br>
['he', 'is', 'a', 'man'],<br>
['she', 'is', 'a', 'woman'],<br>
['warsaw', 'is', 'poland', 'capital'],<br>
['berlin', 'is', 'germany', 'capital'],<br>
['paris', 'is', 'france', 'capital']]</p>
</blockquote>
<p>然后对单词进行编号：</p>
<pre><code class="language-python">vocabulary = []
for sentence in tokenized_corpus:
   for token in sentence:
       if token not in vocabulary:
           vocabulary.append(token)

word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}
idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}

vocabulary_size = len(vocabulary)
</code></pre>
<p>得到结果</p>
<blockquote>
<p>0: 'he',<br>
1: 'is',<br>
2: 'a',<br>
3: 'king',<br>
4: 'she',<br>
5: 'queen',<br>
6: 'man',<br>
7: 'woman',<br>
8: 'warsaw',<br>
9: 'poland',<br>
10: 'capital',<br>
11: 'berlin',<br>
12: 'germany',<br>
13: 'paris',<br>
14: 'france'</p>
</blockquote>
<p>然后可以产生中心词(center word), 上下文词(context word)对，假设窗口为2</p>
<pre><code class="language-python">window_size = 2
idx_pairs = []
# for each sentence
for sentence in tokenized_corpus:
    indices = [word2idx[word] for word in sentence]
    # for each word, threated as center word
    for center_word_pos in range(len(indices)):
        # for each window position
        for w in range(-window_size, window_size + 1):
            context_word_pos = center_word_pos + w
            # make soure not jump out sentence
            if context_word_pos &lt; 0 or context_word_pos &gt;= len(indices) or center_word_pos == context_word_pos:
                continue
            context_word_idx = indices[context_word_pos]
            idx_pairs.append((indices[center_word_pos], context_word_idx))

idx_pairs = np.array(idx_pairs) # it will be useful to have this as numpy array
</code></pre>
<p>得到的结果是</p>
<blockquote>
<p>array([[ 0,  1],<br>
[ 0,  2],<br>
...</p>
</blockquote>
<p>翻译为:</p>
<blockquote>
<p>he is<br>
he a<br>
is he<br>
is a<br>
is king<br>
a he<br>
a is<br>
a king</p>
</blockquote>
<p>用图片展示更佳<br>
<img src="https://lushunn.github.io/post-images/1586852413944.png" alt=""></p>
<h1 id="3定义目标函数">3.定义目标函数</h1>
<p>对于 skip-gram来说，我们感兴趣的概率应该是已知中心词和参数下，上下文词的出现概率，对每一个词对，有<br>
<img src="https://lushunn.github.io/post-images/1586852557983.png" alt=""><br>
我们的模型，应该能使所有词对的以下概率出现最大化：<br>
<img src="https://lushunn.github.io/post-images/1586852637182.png" alt=""><br>
为了为方便求导，对目标函数log处理，并求目标函数最小化：<br>
<img src="https://lushunn.github.io/post-images/1586852719522.png" alt=""><br>
由于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo>(</mo><mi>a</mi><mo separator="true">⋅</mo><mi>b</mi><mo>)</mo><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>a</mi><mo>+</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">log(a·b)=loga+logb</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">⋅</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">b</span></span></span></span>,最后的损失函数为：<br>
<img src="https://lushunn.github.io/post-images/1586852879223.png" alt=""></p>
<p>接下来只剩下定义概率P(context|center)，可以有<br>
<img src="https://lushunn.github.io/post-images/1586852977281.png" alt=""><br>
注意其形式类似于softmax函数。</p>
<h1 id="4coding">4.coding</h1>
<h2 id="input-layer">Input layer</h2>
<p>input layer的作用仅仅是进行one-hot编码</p>
<pre><code class="language-python">def get_input_layer(word_idx):
    x = torch.zeros(vocabulary_size).float()
    x[word_idx] = 1.0
    return x
</code></pre>
<h2 id="hidden-layer">Hidden layer</h2>
<p>隐藏层实质是输入变量和权重的矩阵乘法</p>
<pre><code class="language-python">embedding_dims = 5
W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)
z1 = torch.matmul(W1, x)
</code></pre>
<p>W1的每一列都代表着储存着一个单词的词向量。</p>
<h2 id="output-layer">Output layer</h2>
<pre><code class="language-python">W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)
z2 = torch.matmul(W2, z1)
</code></pre>
<p>最后一层隐藏层有vocabulary_size个神经元，代表着每个单词的出现概率。<br>
输出层：</p>
<pre><code class="language-python">log_softmax = F.log_softmax(a2, dim=0)
</code></pre>
<p>等同于取log后进行softmax的计算效果<br>
最后计算损失函数</p>
<pre><code class="language-python">loss = F.nll_loss(log_softmax.view(1,-1), y_true)
</code></pre>
<p>整体代码如下</p>
<pre><code class="language-python">embedding_dims = 5
W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)
W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)
num_epochs = 100
learning_rate = 0.001

for epo in range(num_epochs):
    loss_val = 0
    for data, target in idx_pairs:
        x = Variable(get_input_layer(data)).float()
        y_true = Variable(torch.from_numpy(np.array([target])).long())

        z1 = torch.matmul(W1, x)
        z2 = torch.matmul(W2, z1)
    
        log_softmax = F.log_softmax(z2, dim=0)

        loss = F.nll_loss(log_softmax.view(1,-1), y_true)
        loss_val += loss.data[0]
        loss.backward()
        W1.data -= learning_rate * W1.grad.data
        W2.data -= learning_rate * W2.grad.data

        W1.grad.data.zero_() #降梯度归0
        W2.grad.data.zero_()#降梯度归0
    if epo % 10 == 0:    
        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')
</code></pre>
<p>当然在训练word2vec的过程中还有很多工程技巧，比如用negative sampling或Hierarchical Softmax减少词汇空间过大带来的计算量，对高频词汇进行降采样避免对于这些低信息词汇的无谓计算等。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[公司内部ML比赛小总结]]></title>
        <id>https://lushunn.github.io/post/gong-si-nei-bu-ml-bi-sai-xiao-zong-jie</id>
        <link href="https://lushunn.github.io/post/gong-si-nei-bu-ml-bi-sai-xiao-zong-jie">
        </link>
        <updated>2020-03-09T14:33:02.000Z</updated>
        <content type="html"><![CDATA[<p>之前零零散散做过一些数据挖掘比赛，由于个人水平原因和偷懒，要么没坚持下来，要么与得奖失之交臂，也就得过一次小小安慰奖，今天痛改前非，小小记录一下公司内部数据挖掘比赛，算是复盘？</p>
<h2 id="0-说明">0. 说明</h2>
<p>本比赛算是初赛，750人参加，排除掉抄袭后最后名次50+。从开始建模提交次数不算多，中间经过了几次tricks导致分数暴涨，涨到前3后就失去了动力，陷入泥淖。过年疫情那段时间被人疯狂赶上。</p>
<h2 id="1-探索性数据分析">1. 探索性数据分析</h2>
<p>比赛赛题是“基于用户行为特征分析的骚扰欺诈电话识别”，任务是多分类，评价指标是F1。<br>
数据标签进行了加密，通过hd5解密可以得到真实label。</p>
<pre><code class="language-python">decode={'7C26FADD409BD4B9':'normal','C7E2941B65C6CCD6':'driver','816A9BEBED2D7C99':'Harassment','0F2E4CC10EDBE80F':'Fraud','56AFA2A526F96CC9'
       :'delivery' }
</code></pre>
<p>所用可视化的方法来自<a href="https://github.com/shenxiangzhuang/Bank-Competition">here</a>作者，原本是二分类的label和features的交叉分析，被我蹩脚的胡改变成多分类，可视化函数如下：</p>
<pre><code class="language-python">import seaborn as sns
import matplotlib.pyplot as plt
#离散特征
def catPlot_5(data,feature, figsize=(14, 6), save=False, filename=None):#是否正常绘图
    df=data.copy(deep=True)
    total=len(df)
    feature_name = feature.capitalize()
    tmp = pd.crosstab(df[feature], df['label'], normalize='index') * 100
    tmp = tmp.reset_index()

    plt.figure(figsize=figsize)
    plt.suptitle(f'{feature_name} Distributions', fontsize=22)

    plt.subplot(121)
    g = sns.countplot(x=feature, data=df)
    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])

    g.set_title(f&quot;{feature_name} Distribution&quot;, fontsize=19)
    g.set_xlabel(feature_name, fontsize=17)
    g.set_ylabel(&quot;Count&quot;, fontsize=17)
    for p in g.patches:
        height = p.get_height()
        g.text(p.get_x()+p.get_width()/2.,
                height + 3,
                '{:1.2f}%'.format(height/total*100),
                ha=&quot;center&quot;, fontsize=14) 

    plt.subplot(122)
    g1 = sns.countplot(x=feature, hue='label', data=df)
    #plt.legend(title='label', loc='best', labels=['No', 'Yes'])
    gt = g1.twinx()
    gt = sns.pointplot(x=feature, y='normal', data=tmp, 
                       color='blue', scale=0.5,
                       legend=False)
    gt = sns.pointplot(x=feature, y='driver', data=tmp, 
                       color='purple', scale=0.5,
                       legend=False)
    gt = sns.pointplot(x=feature, y='delivery', data=tmp, 
                       color='green', scale=0.5,
                       legend=False)
    gt = sns.pointplot(x=feature, y='Harassment', data=tmp, 
                       color='orange', scale=0.5,
                       legend=False)
    gt = sns.pointplot(x=feature, y='Fraud', data=tmp, 
                       color='red', scale=0.5,
                       legend=False)
    #gt.set_ylabel(&quot;% of Fraud Transactions&quot;, fontsize=16)

    #g1.set_title(f&quot;{feature_name} by Target(isFraud)&quot;, fontsize=19)
    g1.set_xlabel(feature_name, fontsize=17)
    g1.set_ylabel(&quot;Count&quot;, fontsize=17)
    plt.subplots_adjust(hspace = 0.6, top = 0.85)
    if save:
        if filename:
            plt.savefig(f'../pics/{filename}.png', bbox_inches='tight', dpi=300)
        else:
            plt.savefig(f'../pics/{feature_name}.png', bbox_inches='tight', dpi=300)
    plt.show()

#连续特征
def distPlot(data,feature, save=False, filename=None):
    df=data.dropna()
    #df['label']=df['label'].map(lambda x : 1 if x&gt;=3 else 0)
    feature_name = feature.capitalize()
    g = sns.distplot(df[df['label'] == 'normal'][feature], label='normal')
    g = sns.distplot(df[df['label'] == 'driver'][feature], label='driver')
    g = sns.distplot(df[df['label'] == 'delivery'][feature], label='delivery')
    g = sns.distplot(df[df['label'] == 'Harassment'][feature], label='Harassment')
    g = sns.distplot(df[df['label'] == 'Fraud'][feature], label='Fraud')
    g.legend()
    g.set_title(f&quot;{feature_name} Distribution by Target&quot;, fontsize=20)
    g.set_xlabel(feature_name, fontsize=18)
    g.set_ylabel(&quot;Probability&quot;, fontsize=18)
    if save:
        if filename:
            plt.savefig(f'../pics/{filename}.png', bbox_inches='tight', dpi=300)
        else:
            plt.savefig(f'../pics/{feature_name}.png', bbox_inches='tight', dpi=300)
    plt.show()
</code></pre>
<p>可视化效果如下<br>
<img src="https://lushunn.github.io/post-images/1583769731867.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1583769758058.png" alt=""></p>
<h2 id="3-建模思路">3. 建模思路</h2>
<p>经过和同事讨论和排名靠全的同事分享，提高得分的诀窍在于train数据和test数据存在分布差别过大，以及数据不均衡的现象。总结来说tricks有三点，stacking增强模型泛化能力，重采样以及调整损失函数。很遗憾其实我只做到了第二点，简单的将label分布最少的样本翻了一倍；模型集成方面用的相较于stacking更简单的10fold交叉验证，每9折数据建立模型预测pred_prob取平均。</p>
<p>1）特征工程</p>
<p>将缺失值统一插补-9999，取值较少的离散变量，如credit_level，gender，做one-hot处理；用户出生日期这个特征上，将取值个数少于10个的一些取值中，找出一些异常取值（如1911）进行特别标注，产品实例开通日期中，异常取值（如大于20190930）特别标注，CUST_ACCESS_NET_DT客户入网时间，只取到年月日，抛弃小时分钟信息，在网产品个数大于250个统一截断为250。生成特征category_visit，汇总应用启动次数大于0的应用之总启动个数。同时删除特征membership_level会员级别和app1_visits（app1的启动次数），特别是去除后者，对预测得分提升极大，其实算是凑巧发现，我猜可能是在这个特征上train和test差别过大，但在train训练的模型中，此特征的特征重要性却远远甩开同类其他app启动特征的缘故。有些id类特征，如终端厂商，手机终端型号，终端厂商会出现id取值过多，且测试集出现不存在于训练集的id取值这种难搞的现象，这类特征我一直都没有找到好的处理方式，用label做woe编码或者做labelcount编码好像都会透露label信息导致预测精度下降；本次处理方法是先将出现频率小于阈值的取值做统一特殊编码，再做count编码，也就是用特征出现的频数来代替原本取值，最后效果还算不错。其实我感觉这类id特征，一般基于业务去提取主要的信息是最好的，工作量当然也会成倍增加。</p>
<p>总得来说，我还是太不了解移动运营商产品的业务知识了，也找不到人去问，所以生成交叉这方面，还是做的挺贫乏的，</p>
<p>2）建模<br>
没啥好说的，lgb干就完了，10折模型去集成，偷懒代替stacking。</p>
<p>3）样本不均衡<br>
除了把样本量最小的样本数翻了一倍之外，对于多分类预测也采用了阈值调整的方法，效果是非常不错的。</p>
<h2 id="4-总结">4. 总结</h2>
<p>之前总以为比赛只要作好特征工程加调参集成就行，其实并不是，还有更基础的数据层面，在这个坑上面我被折腾了很久，比如训练集和测试集分布过大时要怎么处理，要不要针对数据均衡采取处理，还有一些致命的噪声特征（比如取值全部一样，多个特征高强度相关，train和test分布差别过大），有时候很容易忽视，却是一个降低预测精准度的坑。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[写Scala中会用到的一些tips]]></title>
        <id>https://lushunn.github.io/post/xie-scala-zhong-hui-yong-dao-de-yi-xie-tips</id>
        <link href="https://lushunn.github.io/post/xie-scala-zhong-hui-yong-dao-de-yi-xie-tips">
        </link>
        <updated>2020-03-09T09:01:16.000Z</updated>
        <content type="html"><![CDATA[<p>记录工作中会常用到的一些实用例子</p>
<ol>
<li>尼基系数<br>
科学计算方面scala包的丰富性还是略差于python，出于业务需要，需要编写一个计算基尼指数的函数，<br>
<a href="https://www.cnblogs.com/OliverQin/p/8649605.html">here</a>  已经给出了计算方法和应用案例，根据计算过程稍加修改即可：</li>
</ol>
<pre><code class="language-scala"> def gini( nums :ArrayBuffer[Int]): Double={

 def scanLeft[a,b](xs:Iterable[a])(s:b)(f : (b,a) =&gt; b) =
   xs.foldLeft(List(s))( (acc,x) =&gt; f(acc(0), x) :: acc).reverse //累加函数
 
 val nums_1=nums.sorted
 val y_cumsum=scanLeft(nums_1)(0)(_+_)
 val y_sum=nums.sum
 val y_per_cumsum=y_cumsum.map(x=&gt;x.toDouble/y_sum)
 
 val x = List.fill(nums.length)(1.0)
 val x_sum=x.sumstako
 val x_cumsum=scanLeft(x)(0.0)(_+_)
 val x_per_cumsum=x_cumsum.map(x=&gt;x/x_sum)
 val pairs = x_per_cumsum zip y_per_cumsum
 var B=0.0
 val l=pairs.length
 for (i &lt;- 1 until l) {
   B+=(pairs(i)._2+pairs(i-1)._2)*(pairs(i)._1-pairs(i-1)._1)*0.5
 }
 val A = 0.5 - B
 A / (A + B)
}
</code></pre>
<ul>
<li>刚开始使用scala，说实话自认写的挺烂，风格不够scala有优化空间，scanLeft我也是抄自<a href="https://stackoverflow.com/questions/3224935/in-scala-how-do-i-fold-a-list-and-return-the-intermediate-results">stackoverflow</a>,说实话没太看懂，希望之后会更进步。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《推荐系统实践》 读书笔记 第7-8章（撒花完结）]]></title>
        <id>https://lushunn.github.io/post/lesslesstui-jian-xi-tong-shi-jian-greatergreater-du-shu-bi-ji-di-7-8-zhang-sa-hua-wan-jie</id>
        <link href="https://lushunn.github.io/post/lesslesstui-jian-xi-tong-shi-jian-greatergreater-du-shu-bi-ji-di-7-8-zhang-sa-hua-wan-jie">
        </link>
        <updated>2019-12-09T14:44:11.000Z</updated>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E4%BE%8B">推荐系统实例</a>
<ul>
<li><a href="#%E5%A4%96%E5%9B%B4%E6%9E%B6%E6%9E%84">外围架构</a></li>
<li><a href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84">推荐系统架构</a></li>
<li><a href="#%E6%8E%A8%E8%8D%90%E5%BC%95%E6%93%8E%E7%9A%84%E6%9E%B6%E6%9E%84">推荐引擎的架构</a>
<ul>
<li><a href="#%E7%94%9F%E6%88%90%E7%94%A8%E6%88%B7%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F">生成用户特征向量</a></li>
<li><a href="#%E7%89%B9%E5%BE%81%E7%89%A9%E5%93%81%E7%9B%B8%E5%85%B3%E6%8E%A8%E8%8D%90">特征—物品相关推荐</a></li>
<li><a href="#%E8%BF%87%E6%BB%A4%E6%A8%A1%E5%9D%97">过滤模块</a></li>
<li><a href="#%E6%8E%92%E5%90%8D%E6%A8%A1%E5%9D%97">排名模块</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E8%AF%84%E5%88%86%E9%A2%84%E6%B5%8B%E9%97%AE%E9%A2%98">评分预测问题</a>
<ul>
<li><a href="#%E8%AF%84%E5%88%86%E9%A2%84%E6%B5%8B%E7%AE%97%E6%B3%95">评分预测算法</a>
<ul>
<li><a href="#%E5%B9%B3%E5%9D%87%E5%80%BC">平均值</a>
<ul>
<li><a href="#%E7%94%A8%E6%88%B7%E5%88%86%E7%B1%BB%E5%AF%B9%E7%89%A9%E5%93%81%E5%88%86%E7%B1%BB%E7%9A%84%E5%B9%B3%E5%9D%87%E5%80%BC">用户分类对物品分类的平均值</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E9%82%BB%E5%9F%9F%E7%9A%84%E6%96%B9%E6%B3%95">基于邻域的方法</a></li>
<li><a href="#%E9%9A%90%E8%AF%AD%E4%B9%89%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E6%A8%A1%E5%9E%8B">隐语义模型与矩阵分解模型</a></li>
<li><a href="#%E5%8A%A0%E5%85%A5%E6%97%B6%E9%97%B4%E4%BF%A1%E6%81%AF">加入时间信息</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88">模型融合</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</p>
<h1 id="推荐系统实例">推荐系统实例</h1>
<h2 id="外围架构">外围架构</h2>
<p><img src="https://lushunn.github.io/post-images/1575902726242.png" alt=""><br>
一般来说，需要实时存取的数据存储在数据库和缓存中，而大规模的非实时地存取数据存储在分布式<br>
文件系统（如HDFS）中。数据能否实时存取在推荐系统中非常重要，因为推荐系统的实时性主要依赖于能否实时拿到用户的新行为。只有快速拿到大量用户的新行为，推荐系统才能够实时地适应用户当前的需求，<br>
给用户进行实时推荐。</p>
<h2 id="推荐系统架构">推荐系统架构</h2>
<p>推荐系统需要由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务，而推荐系统的任务只是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回。<br>
<img src="https://lushunn.github.io/post-images/1575902890988.png" alt=""><br>
好处：</p>
<ul>
<li>可以方便地增加/删除引擎，控制不同引擎对推荐结果的影响。</li>
<li>可以实现推荐引擎级别的用户反馈。</li>
</ul>
<h2 id="推荐引擎的架构">推荐引擎的架构</h2>
<figure data-type="image" tabindex="1"><img src="https://lushunn.github.io/post-images/1575990317173.png" alt=""></figure>
<ul>
<li>A负责从数据库或者缓存中拿到用户行为数据，通过分析不同行为，生成当前用户的特征向量。不过如果是使用非行为特征，就不需要使用行为提取和分析模块了。该模块的输出是用户特征向量。</li>
<li>B负责将用户的特征向量通过特征-物品相关矩阵转化为初始推荐物品列表。</li>
<li>C负责对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。</li>
</ul>
<h3 id="生成用户特征向量">生成用户特征向量</h3>
<p>用户的特征包括两种，一种是用户的注册信息中可以提取出来的，另一种特征主要是从用户的行为中计算出来的。<br>
一个特征向量由特征以及特征的权重组成，在利用用户行为计算特征向量时需要考虑以下因素。</p>
<ul>
<li>用户行为的种类</li>
<li>用户行为产生的时间</li>
<li>用户行为的次数</li>
<li>物品的热门程度</li>
</ul>
<h3 id="特征物品相关推荐">特征—物品相关推荐</h3>
<p>在得到用户的特征向量后，可以根据离线的相关表得到初始的物品推荐列表，存储和它最相关的N个物品的ID。特征—物品相关推荐模块还可以接受一个候选物品集合。候选物品集合的目的是保证推荐结果只包含候选物品集合中的物品。<br>
什么不在过滤模块中过滤掉不在候选集中的物品：防止错失推荐低热度的物品。（候选物品集合较小的情况下）</p>
<h3 id="过滤模块">过滤模块</h3>
<p>在得到初步的推荐列表后，还不能把这个列表展现给用户，首先需要按照产品需求对结果进<br>
行过滤，过滤掉那些不符合要求的物品。</p>
<ul>
<li>用户已经产生过行为物品</li>
<li>候选物品以外的物品</li>
<li>某些质量很差的物品</li>
</ul>
<h3 id="排名模块">排名模块</h3>
<ol>
<li>新颖性排名<br>
<img src="https://lushunn.github.io/post-images/1576068389198.png" alt=""></li>
<li>多样性<br>
第一种提高多样性的方法是将推荐结果按照某种物品的内容属性分成几类，然后在每个类中<br>
都选择该类中排名最高的物品组合成最终的推荐列表。第二种提高推荐结果多样性的方法是控制不同推荐结果的推荐理由出现的次数。</li>
<li>时间多样性<br>
时间多样性主要是为了保证用户不要每天来推荐系统都看到同样的推荐结果。</li>
</ol>
<ul>
<li>记录用户每次登陆推荐系统看到的推荐结果。</li>
<li>将这些结果发回日志系统。这种数据不需要实时存储，只要能保证小于一天的延时就足<br>
够了。</li>
<li>在用户登录时拿到用户昨天及之前看过的推荐结果列表，从当前推荐结果中将用户已经<br>
看到的推荐结果降权。</li>
</ul>
<ol start="4">
<li>用户反馈<br>
排名模块最重要的部分就是用户反馈模块。用户反馈模块主要通过分析用户之前和推荐结果<br>
的交互日志，预测用户会对什么样的推荐结果比较感兴趣。<br>
如果推荐系统的目标是提高用户对推荐结果的点击率，那么可以利用点击模型（click model）<br>
预测用户是否会点击推荐结果。点击率预测中可以用如下特征预测用户u会不会点击物品i：</li>
</ol>
<ul>
<li>用户u相关的特征，比如年龄、性别、活跃程度、之前有没有点击行为；</li>
<li>物品i相关的特征，比如流行度，平均分，内容属性；</li>
<li>物品i在推荐列表中的位置。用户的点击和用户界面的设计有很高的相关性，因此物品i在<br>
推荐列表中的位置对预测用户是否点击很重要；</li>
<li>用户之前是否点击过和推荐物品i具有同样推荐解释的其他推荐结果；</li>
<li>用户之前是否点击过和推荐物品i来自同样推荐引擎的其他推荐结果。</li>
</ul>
<h1 id="评分预测问题">评分预测问题</h1>
<h2 id="评分预测算法">评分预测算法</h2>
<h3 id="平均值">平均值</h3>
<p>最简单的评分预测算法是利用平均值预测用户对物品的评分的。</p>
<h4 id="用户分类对物品分类的平均值">用户分类对物品分类的平均值</h4>
<figure data-type="image" tabindex="2"><img src="https://lushunn.github.io/post-images/1576069195460.png" alt=""></figure>
<h4 id="基于邻域的方法">基于邻域的方法</h4>
<p><img src="https://lushunn.github.io/post-images/1576069380433.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1576069415145.png" alt=""></p>
<h4 id="隐语义模型与矩阵分解模型">隐语义模型与矩阵分解模型</h4>
<p>用户的评分行为可以表示成一个评分矩阵R，其中R[u][i]就是用户u对物品i的评分。但是，用户不会对所有的物品评分，所以这个矩阵里有很多元素都是空的，评分预测从某种意义上说就是填空。<br>
1.传统的SVD分解<br>
给定m个用户和n个物品，和用户对物品<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">R\inℝ^{m \times n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.771331em;vertical-align:0em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>。首先需要对评分矩阵中的缺失值进行简单地补全，比如用全局平均值，或者用户/物品平均值补全，得到补全后的矩阵R'。接着，可以用SVD分解将R'分解成如下形式：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>R</mi><mo mathvariant="normal">′</mo></msup><mo>=</mo><msup><mi>U</mi><mi>T</mi></msup><mi>S</mi><mi>V</mi></mrow><annotation encoding="application/x-tex">R&#x27;=U^TSV
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.801892em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8913309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mrow><mi>k</mi><mo>×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">U \inℝ^{k \times m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight">m</span></span></span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mrow><mi>k</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">V \inℝ^{k \times n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>是两个正交矩阵，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mrow><mi>k</mi><mo>×</mo><mi>k</mi></mrow></msup></mrow><annotation encoding="application/x-tex">S \inℝ^{k \times k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span></span>是对角阵，对角线上的每一个元素都是矩阵的奇异值。为了对R'进行降维，可以取最大的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span></span></span></span>个奇异值组成对角矩阵<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">S_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，并且找到这<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span></span></span></span>个奇异值中每个值在U、V矩阵中对应的行和列，得到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>U</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">U_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>V</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">V_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，从而可以得到一个降维后的评分矩阵：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>R</mi><mi>f</mi><mo mathvariant="normal">′</mo></msubsup><mo>=</mo><msubsup><mi>U</mi><mi>f</mi><mi>T</mi></msubsup><msub><mi>S</mi><mi>f</mi></msub><msub><mi>V</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">R_f&#x27;=U_f^TS_fV_f
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-2.4530000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.274439em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.891331em;"><span style="top:-2.4530000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中， <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>R</mi><mi>f</mi><mo mathvariant="normal">′</mo></msubsup><mo>(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">R_f&#x27;(u,i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1711079999999998em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span> 就是用户u对物品i评分的预测值。<br>
缺点：</p>
<ul>
<li>补全后变稠密矩阵，消耗内存空间。</li>
<li>计算复杂度很高</li>
</ul>
<ol start="2">
<li>Simon Funk的SVD分解<br>
<img src="https://lushunn.github.io/post-images/1576072524954.png" alt=""></li>
<li>加入偏置项后的LFM<br>
<img src="https://lushunn.github.io/post-images/1576072609974.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1576072614699.png" alt=""></li>
<li>考虑邻域影响的LFM<br>
前面的LFM模型中并没有显式地考虑用户的历史行为对用户评分预测的影响，提出SVD++。<br>
<img src="https://lushunn.github.io/post-images/1576072706266.png" alt=""></li>
</ol>
<h4 id="加入时间信息">加入时间信息</h4>
<ol>
<li>基于邻域的模型融合时间信息<br>
<img src="https://lushunn.github.io/post-images/1576072781297.png" alt=""></li>
<li>基于矩阵分解的模型融合时间信息<br>
在引入时间信息后，用户评分矩阵不再是一个二维矩阵，而是变成了一个三维矩阵。我们可以仿照分解二维矩阵的方式对三维矩阵进行分解。<br>
<img src="https://lushunn.github.io/post-images/1576072903806.png" alt=""></li>
</ol>
<h4 id="模型融合">模型融合</h4>
<ol>
<li>模型级联融合</li>
<li>模型加权融合</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《推荐系统实践》 读书笔记 第5-6章]]></title>
        <id>https://lushunn.github.io/post/lesslesstui-jian-xi-tong-shi-jian-greatergreater-du-shu-bi-ji-di-5-6-zhang</id>
        <link href="https://lushunn.github.io/post/lesslesstui-jian-xi-tong-shi-jian-greatergreater-du-shu-bi-ji-di-5-6-zhang">
        </link>
        <updated>2019-12-06T15:59:37.000Z</updated>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#%E5%88%A9%E7%94%A8%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF">利用上下文信息</a>
<ul>
<li><a href="#%E6%97%B6%E9%97%B4%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF">时间上下文信息</a>
<ul>
<li><a href="#%E6%97%B6%E9%97%B4%E6%95%88%E5%BA%94%E7%AE%80%E4%BB%8B">时间效应简介</a></li>
<li><a href="#%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4%E7%89%B9%E6%80%A7%E7%9A%84%E5%88%86%E6%9E%90">系统时间特性的分析</a></li>
<li><a href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%9E%E6%97%B6%E6%80%A7">推荐系统的实时性</a></li>
<li><a href="#%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%9A%E6%A0%B7%E6%80%A7">推荐算法的时间多样性</a></li>
<li><a href="#%E6%97%B6%E9%97%B4%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95">时间上下文推荐算法</a></li>
<li><a href="#%E6%97%B6%E9%97%B4%E6%AE%B5%E5%9B%BE%E6%A8%A1%E5%9E%8B">时间段图模型</a></li>
</ul>
</li>
<li><a href="#%E5%9C%B0%E7%82%B9%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF">地点上下文信息</a>
<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%BD%AE%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95">基于位置的推荐算法</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%88%A9%E7%94%A8%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE">利用社交网络数据</a>
<ul>
<li><a href="#%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%E9%95%BF%E5%B0%BE%E5%88%86%E5%B8%83">社交网络数据中的长尾分布</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E7%9A%84%E6%8E%A8%E8%8D%90">基于社交网络的推荐</a>
<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E9%82%BB%E5%9F%9F%E7%9A%84%E7%A4%BE%E4%BC%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95">基于邻域的社会化推荐算法</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E7%A4%BE%E4%BC%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95">基于图的社会化推荐算法</a></li>
<li><a href="#%E5%AE%9E%E9%99%85%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E7%A4%BE%E4%BC%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95">实际系统中的社会化推荐算法</a></li>
<li><a href="#%E7%A4%BE%E4%BC%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F">社会化推荐系统和协同过滤推荐系统</a></li>
<li><a href="#%E4%BF%A1%E6%81%AF%E6%B5%81%E6%8E%A8%E8%8D%90">信息流推荐</a></li>
</ul>
</li>
<li><a href="#%E7%BB%99%E7%94%A8%E6%88%B7%E6%8E%A8%E8%8D%90%E5%A5%BD%E5%8F%8B">给用户推荐好友</a>
<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E5%8C%B9%E9%85%8D">基于内容的匹配</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%85%B1%E5%90%8C%E5%85%B4%E8%B6%A3%E7%9A%84%E5%A5%BD%E5%8F%8B%E6%8E%A8%E8%8D%90">基于共同兴趣的好友推荐</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%9B%BE%E7%9A%84%E5%A5%BD%E5%8F%8B%E6%8E%A8%E8%8D%90">基于社交网络图的好友推荐</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</p>
<h1 id="利用上下文信息">利用上下文信息</h1>
<h2 id="时间上下文信息">时间上下文信息</h2>
<h3 id="时间效应简介">时间效应简介</h3>
<ul>
<li>用户兴趣是变化的</li>
<li>物品也是有生命周期的</li>
<li>季节效应</li>
</ul>
<h3 id="系统时间特性的分析">系统时间特性的分析</h3>
<ul>
<li>数据集每天独立用户数的增长情况：有些网站处于快速增长期，而有些网站处于平稳期或衰落期。</li>
<li>系统的物品变化情况</li>
<li>用户访问情况<br>
物品的生存周期和系统的时效性：</li>
<li>物品平均在线天数</li>
<li>相隔T天系统物品流行度向量的平均相似度</li>
</ul>
<h3 id="推荐系统的实时性">推荐系统的实时性</h3>
<ul>
<li>实时推荐系统不能每天都给所有用户离线计算推荐结果，然后在线展示昨天计算出来的<br>
结果。所以，要求在每个用户访问推荐系统时，都根据用户这个时间点前的行为实时计<br>
算推荐列表。</li>
<li>推荐算法需要平衡考虑用户的近期行为和长期行为，即要让推荐列表反应出用户近期行<br>
为所体现的兴趣变化，又不能让推荐列表完全受用户近期行为的影响，要保证推荐列表<br>
对用户兴趣预测的延续性。</li>
</ul>
<h3 id="推荐算法的时间多样性">推荐算法的时间多样性</h3>
<p>需求：</p>
<ul>
<li>保证推荐系统能够在用户有了新的行为后及时调整推荐结果，使推荐结果满足用户最近的兴趣；</li>
<li>需要保证推荐系统在用户没有新的行为时也能够经常变化一下结果，具有一定的时间多样性。<br>
解决方案：</li>
<li>在生成推荐结果时加入一定的随机性。</li>
<li>记录用户每天看到的推荐结果，然后在每天给用户进行推荐时，对他前几天看到过很多次的推荐结果进行适当地降权。</li>
<li>每天给用户使用不同的推荐算法。</li>
</ul>
<h3 id="时间上下文推荐算法">时间上下文推荐算法</h3>
<ol>
<li>最近最热门<br>
<img src="https://lushunn.github.io/post-images/1575897352695.png" alt=""></li>
<li>时间上下文相关的ItemCF算法<br>
算法组成：</li>
</ol>
<ul>
<li>利用用户行为离线计算物品之间的相似度</li>
<li>根据用户的历史行为和物品相似度矩阵，给用户做在线个性化推荐。<br>
时间信息的体现：</li>
<li>物品相似度：用户在相隔很短的时间内喜欢的物品具有更高相似度。</li>
<li>在线推荐：用户近期行为相比用户很久之前的行为，更能体现用户现在的兴趣。<br>
<img src="https://lushunn.github.io/post-images/1575897486751.png" alt=""><br>
修正预测公式：<br>
<img src="https://lushunn.github.io/post-images/1575897601409.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575897606499.png" alt=""></li>
</ul>
<ol start="3">
<li>时间上下文相关的UserCF算法<br>
<img src="https://lushunn.github.io/post-images/1575897790063.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575897802806.png" alt=""></li>
</ol>
<h3 id="时间段图模型">时间段图模型</h3>
<p><img src="https://lushunn.github.io/post-images/1575897852726.png" alt=""><br>
优化方法：<br>
PersonalRank算法时间复杂度高，提出路径融合算法的方法。<br>
两个相关性比较高的顶点一般具有如下特征：</p>
<ol>
<li>两个顶点之间有很多路径相连；</li>
<li>两个顶点之间的路径比较短；</li>
<li>个顶点之间的路径不经过出度比较大的顶点。<br>
<img src="https://lushunn.github.io/post-images/1575897923589.png" alt=""></li>
</ol>
<h2 id="地点上下文信息">地点上下文信息</h2>
<h3 id="基于位置的推荐算法">基于位置的推荐算法</h3>
<p>数据集有3种不同的形式：</p>
<ul>
<li>（用户，用户位置，物品，评分）</li>
<li>（用户，物品，物品位置，评分）</li>
<li>（用户，用户位置，物品，物品位置，评分）<br>
用户兴趣和地点相关的两种特征：</li>
<li>兴趣本地化：不同地方的用户兴趣存在着很大的差别。</li>
<li>活动本地化：一个用户往往在附近的地区活动。<br>
针对三种数据集对应的方法：</li>
</ul>
<ol>
<li>利用用户地理位置的树状结构特点（国家、省、市、县的结构），从根节点出发，在到叶子节点的过程<br>
中，利用每个中间节点上的数据训练出一个推荐模型，然后给用户生成推荐列表。而最终的推荐结果是这一系列推荐列表的加权。</li>
<li>物品i在用户u的推荐列表中的权重：</li>
</ol>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>S</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo>)</mo><mo>−</mo><mi>T</mi><mi>r</mi><mi>a</mi><mi>v</mi><mi>e</mi><mi>l</mi><mi>P</mi><mi>e</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi>t</mi><mi>y</mi><mo>(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">RecScore( u,i) = P(u,i) - TravelPenalty(u,i) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span></span></p>
<p>用户u对物品i的兴趣<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">P(u,i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>a</mi><mi>v</mi><mi>e</mi><mi>l</mi><mi>P</mi><mi>e</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi>t</mi><mi>y</mi><mo>(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">ravelPenalty(u,i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span>表示了物品i的位置对用户u的代价,基本思想是对于物品i与用户u之前评分的所有物品的位置计算距离的平均值(如欧式距离）。为了避免计算用户对所有物品的TravelPenalty，LARS在计算用户u对物品i的兴趣度RecScore(u,i)时，首先对用户每一个曾经评过分的物品（一般是餐馆、商店、景点），找到和他距离小于一个阈值d的所有其他物品。<br>
3. 应保证推荐的物品应该距离用户当前位置比较近，在此基础上再通过用户的历史行为给用户推荐离他近且他会感兴趣的物品。</p>
<h1 id="利用社交网络数据">利用社交网络数据</h1>
<p>社交网络定义了用户之间的联系，因此可以用图定义社交网络。我们用图<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi><mo>(</mo><mi>V</mi><mo separator="true">,</mo><mi>E</mi><mo separator="true">,</mo><mi>w</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">G(V,E,w)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">G</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span></span></span></span>定义一个<br>
社交网络，其中V是顶点集合，每个顶点代表一个用户，E是边集合，如果用户<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">v_a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">v_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>有社交网络<br>
关系，那么就有一条边<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>e</mi><mo>(</mo><msub><mi>v</mi><mi>a</mi></msub><mo separator="true">,</mo><msub><mi>v</mi><mi>b</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">e(v_a ,v_b )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>连接这两个用户，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>(</mo><msub><mi>v</mi><mi>a</mi></msub><mo separator="true">,</mo><msub><mi>v</mi><mi>b</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">w(v_a ,v_b )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>定义了边的权重。<br>
分类：</p>
<ol>
<li>双向确认的社交网络数据 无向图</li>
<li>单向关注的社交网络数据 有向图</li>
<li>基于社区的社交网络数据</li>
</ol>
<h2 id="社交网络数据中的长尾分布">社交网络数据中的长尾分布</h2>
<ol>
<li>社交网络中影响力大的用户总是占少数。</li>
<li>而绝大多数用户只关注很少的人。</li>
</ol>
<h2 id="基于社交网络的推荐">基于社交网络的推荐</h2>
<p>优点<br>
1: 好友推荐可以增加推荐的信任度<br>
2: 社交网络可以解决冷启动问题</p>
<h3 id="基于邻域的社会化推荐算法">基于邻域的社会化推荐算法</h3>
<figure data-type="image" tabindex="1"><img src="https://lushunn.github.io/post-images/1575899473277.png" alt=""></figure>
<h3 id="基于图的社会化推荐算法">基于图的社会化推荐算法</h3>
<p>如果用户u对物品i产生过行为，那么两个节点之间就有边相连。比如该图中用户A对物品a、e产生过行为。如果用户u和用户v是好友，那么也会有一条边连接这两个用户，比如该图中用户A就和用户B、D是好友。<br>
<img src="https://lushunn.github.io/post-images/1575899679801.png" alt=""></p>
<p>在定义完图中的顶点和边后，需要定义边的权重。其中用户和用户之间边的权重可以定义为<br>
用户之间相似度的a 倍（包括熟悉程度和兴趣相似度），而用户和物品之间的权重可以定义为用<br>
户对物品喜欢程度的b 倍。a 和b 需要根据应用的需求确定。如果我们希望用户好友的行为对<br>
推荐结果产生比较大的影响，那么就可以选择比较大的a 。相反，如果我们希望用户的历史行为<br>
对推荐结果产生比较大的影响，就可以选择比较大的b。<br>
定义完顶点、边和边的权重后，就可以利用PersonalRank图排序算法给每个用户生成推荐结果。<br>
基于社区的社交网络数据推荐方法：<br>
<img src="https://lushunn.github.io/post-images/1575899797131.png" alt=""></p>
<h3 id="实际系统中的社会化推荐算法">实际系统中的社会化推荐算法</h3>
<p>将Twitter的架构搬到社会化推荐系统中，我们就可以按照如下方式设计系统：</p>
<ul>
<li>首先，为每个用户维护一个消息队列，用于存储他的推荐列表；</li>
<li>当一个用户喜欢一个物品时，就将（物品ID、用户ID和时间）这条记录写入关注该用户<br>
的推荐列表消息队列中；</li>
<li>当用户访问推荐系统时，读出他的推荐列表消息队列，对于这个消息队列中的每个物品，<br>
重新计算该物品的权重。计算权重时需要考虑物品在队列中出现的次数，物品对应的用<br>
户和当前用户的熟悉程度、物品的时间戳。同时，计算出每个物品被哪些好友喜欢过，<br>
用这些好友作为物品的推荐解释。</li>
</ul>
<h3 id="社会化推荐系统和协同过滤推荐系统">社会化推荐系统和协同过滤推荐系统</h3>
<p>社会化推荐系统的效果往往很难通过离线实验评测,1)社会化推荐的优势不在于增加预测准确<br>
度，而是在于通过用户的好友增加用户对推荐结果的信任度，从而让用户单击那些很冷门的推荐<br>
结果。2)很多社交网站（特别是基于社交图谱的社交网站）中具有好友关系的用户并不一定<br>
有相似的兴趣。</p>
<h3 id="信息流推荐">信息流推荐</h3>
<p>目的：如何从信息墙中挑选有用的评论。虽然我们在选择关注时已经考虑了关注对象和自己兴趣的相似度，但显然我们无法找到和自己兴趣完全一致的人。<br>
Facebook的EdgeRank：<br>
Facebook将其他用户对当前用户信息流中的会话产生过行为的行为称为edge，而一条会话的权重定义为：<br>
<img src="https://lushunn.github.io/post-images/1575900412144.png" alt=""></p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>u</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">u_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>指产生行为的用户和当前用户的相似度，这里的相似度主要是在社交网络图中的熟悉度；</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">w_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 指行为的权重，这里的行为包括创建、评论、like（喜欢）、打标签等，不同的行为有<br>
不同的权重。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">d_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>指时间衰减参数，越早的行为对权重的影响越低。<br>
EdgeRank算法的个性化因素仅仅是好友的熟悉度，它并没有考虑帖子内容和用户兴趣的相似度。所以EdgeRank仅仅考虑了“我”周围用户的社会化兴趣，而没有重视“我”个人的个性化兴趣。<br>
可考虑如下因素：</li>
<li>会话的长度</li>
<li>话题相关性</li>
<li>用户熟悉程度</li>
</ul>
<h2 id="给用户推荐好友">给用户推荐好友</h2>
<h3 id="基于内容的匹配">基于内容的匹配</h3>
<ol>
<li>用户人口统计学属性，包括年龄、性别、职业、毕业学校和工作单位等。</li>
<li>用户的兴趣，包括用户喜欢的物品和发布过的言论等。</li>
<li>用户的位置信息，包括用户的住址、IP地址和邮编等。</li>
</ol>
<h3 id="基于共同兴趣的好友推荐">基于共同兴趣的好友推荐</h3>
<p>用户的协同过滤算法（UserCF），在新浪微博中，可以将微博看做物品，如果两个用户曾经评论或者转发同样的微博，说明他们具有相似的兴趣。此外，也可以根据用户在社交网络中的发言提取用户的兴趣标签，来计算用户的兴趣相似度。</p>
<h3 id="基于社交网络图的好友推荐">基于社交网络图的好友推荐</h3>
<p><img src="https://lushunn.github.io/post-images/1575900819808.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575900823417.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575900827049.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575900830222.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《推荐系统实践》 读书笔记 第3-4章]]></title>
        <id>https://lushunn.github.io/post/lesslesstui-jian-xi-tong-shi-jian-greatergreater-du-shu-bi-ji-di-3-4-zhang</id>
        <link href="https://lushunn.github.io/post/lesslesstui-jian-xi-tong-shi-jian-greatergreater-du-shu-bi-ji-di-3-4-zhang">
        </link>
        <updated>2019-12-05T13:18:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="目录">目录</h1>
<!-- TOC -->
<ul>
<li><a href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98">第三章 推荐系统冷启动问题</a>
<ul>
<li><a href="#%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98%E7%AE%80%E4%BB%8B">冷启动问题简介</a></li>
<li><a href="#%E5%88%A9%E7%94%A8%E7%94%A8%E6%88%B7%E6%B3%A8%E5%86%8C%E4%BF%A1%E6%81%AF">利用用户注册信息</a></li>
<li><a href="#%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E7%89%A9%E5%93%81%E5%90%AF%E5%8A%A8%E7%94%A8%E6%88%B7%E7%9A%84%E5%85%B4%E8%B6%A3">选择合适的物品启动用户的兴趣</a></li>
<li><a href="#%E5%88%A9%E7%94%A8%E7%89%A9%E5%93%81%E7%9A%84%E5%86%85%E5%AE%B9%E4%BF%A1%E6%81%AF">利用物品的内容信息</a></li>
<li><a href="#%E5%8F%91%E6%8C%A5%E4%B8%93%E5%AE%B6%E7%9A%84%E4%BD%9C%E7%94%A8">发挥专家的作用</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%88%A9%E7%94%A8%E7%94%A8%E6%88%B7%E6%A0%87%E7%AD%BE%E6%95%B0%E6%8D%AE">第四章 利用用户标签数据</a>
<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E6%A0%87%E7%AD%BE%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F">基于标签的推荐系统</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95">基于图的推荐算法</a></li>
<li><a href="#%E7%94%A8%E5%9B%BE%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A%E5%89%8D%E9%9D%A2%E7%9A%84%E7%AE%80%E5%8D%95%E7%AE%97%E6%B3%95">用图模型解释前面的简单算法</a></li>
<li><a href="#%E7%BB%99%E7%94%A8%E6%88%B7%E6%8E%A8%E8%8D%90%E6%A0%87%E7%AD%BE">给用户推荐标签</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<h1 id="第三章-推荐系统冷启动问题">第三章 推荐系统冷启动问题</h1>
<h2 id="冷启动问题简介">冷启动问题简介</h2>
<p>1.用户冷启动 2.物品冷启动3.系统冷启动<br>
解决方法：<br>
1.提供非个性化的推荐如热门排行榜<br>
2.利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。<br>
3.利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。<br>
4.要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。<br>
5.对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。<br>
6.在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。</p>
<h2 id="利用用户注册信息">利用用户注册信息</h2>
<p><img src="https://lushunn.github.io/post-images/1575552594870.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575552685989.png" alt=""></p>
<h2 id="选择合适的物品启动用户的兴趣">选择合适的物品启动用户的兴趣</h2>
<p>解决用户冷启动问题的另一个方法是在新用户第一次访问推荐系统时，不立即给用户展示推荐结果，而是给用户提供一些物品，让用户反馈他们对这些物品的兴趣，然后根据用户反馈给提供个性化推荐。<br>
启动用户兴趣的物品需要具有以下特点:<br>
1.比较热门<br>
2.具有代表性和区分性<br>
区分度<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">D(i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span>:<br>
<img src="https://lushunn.github.io/post-images/1575552918836.png" alt=""><br>
3.启动物品集合需要有多样性</p>
<p>Nadav Golbandi的算法:首先会从所有用户中找到具有最高区分度的物品i，然后将用户分成3<br>
类。然后在每类用户中再找到最具区分度的物品，然后将每一类用户又各自分为3类，也就是将<br>
总用户分成9类，然后这样继续下去，最终可以通过对一系列物品的看法将用户进行分类。而在<br>
冷启动时，我们从根节点开始询问用户对该节点物品的看法，然后根据用户的选择将用户放到不<br>
同的分枝，直到进入最后的叶子节点，此时我们就已经对用户的兴趣有了比较清楚的了解，从而<br>
可以开始对用户进行比较准确地个性化推荐。</p>
<h2 id="利用物品的内容信息">利用物品的内容信息</h2>
<p>tips:，UserCF算法对物品冷启动问题并不非常敏感。因为，UserCF在给用户进行推荐时，会首先找到和用户兴趣相似的一群用户，然后给用户推荐这一群用户喜欢的物品。对于ItemCF算法来说，物品冷启动就是一个严重的问题了。因为ItemCF算法的原理是给用户推荐和他之前喜欢的物品相似的物品。<br>
<img src="https://lushunn.github.io/post-images/1575553362721.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575553403883.png" alt=""><br>
对物品d，它的内容表示成一个关键词向量如下：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>i</mi></msub><mo>=</mo><mo>{</mo><mo>(</mo><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>1</mn></msub><mo>)</mo><mo separator="true">,</mo><mo>(</mo><msub><mi>e</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo>)</mo><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>}</mo></mrow><annotation encoding="application/x-tex">d_i=\{(e_1,w_1),(e_2,w_2 ),...\}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mclose">}</span></span></span></span></span></p>
<p>其中， e_i 就是关键词， w_i 是关键词对应的权重。如果物品是文本，我们可以用信息检索领域著<br>
名的TF-IDF公式计算词的权重：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>T</mi><mi>F</mi><mo>(</mo><msub><mi>e</mi><mi>i</mi></msub><mo>)</mo></mrow><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>D</mi><mi>F</mi><mo>(</mo><msub><mi>e</mi><mi>i</mi></msub><mo>)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">w_i={TF(e_i)\over logDF(e_i)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p>
<p><img src="https://lushunn.github.io/post-images/1575553718351.png" alt=""><br>
tips:向量空间模型在内容数据丰富时可以获得比较好的效果。以文本为例，如果是计算长文本的相似度，用向量空间模型利用关键词计算相似度已经可以获得很高的精确度。但是，如果文本很短，关键词很少，向量空间模型就很难计算出准确的相似度。<br>
针对物品内容信息的词不同，但含义类似的情况，首先需要知道文章的话题分布，然后才能准确地计算文章的相似度。如何建立文章、话题和关键词的关系是话题模型（topic model）研究的重点。<br>
LDA模型：<br>
LDA作为一种生成模型，对一篇文档产生的过程进行了建模。话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。LDA中有3种元素，即文档、话题和词语。每一篇文档都会表现为词的集合，这称为词袋模型(bag of words)。每个词在一篇文章中属于一个话题。令D为文档集合，D[i]第i篇文档。w[i][j]是第i篇文档中的第j个词。z[i][j]是第i篇文档中第j个词属于的话题。<br>
LDA的计算过程包括初始化和迭代两部分。首先要对z进行初始化，而初始化的方法很简单，假设一共有K个话题，那么对第i篇文章中的第j个词，可以随机给它赋予一个话题。同时，用NWZ(w,z)记录词w被赋予话题z的次数，NZD(z,d)记录文档d中被赋予话题z的词的个数。在初始化之后，要通过迭代使话题的分布收敛到一个合理的分布上去。<br>
在使用LDA计算物品的内容相似度时，我们可以先计算出物品在话题上的分布，然后利用两个物品的话题分布计算物品的相似度。比如，如果两个物品的话题分布相似，则认为两个物品具有较高的相似度，反之则认为两个物品的相似度较低。计算分布的相似度可以利用KL散度：<br>
<img src="https://lushunn.github.io/post-images/1575554567439.png" alt=""></p>
<h2 id="发挥专家的作用">发挥专家的作用</h2>
<p>专家和机器学习结合进行内容标记。</p>
<h1 id="第四章-利用用户标签数据">第四章 利用用户标签数据</h1>
<h2 id="基于标签的推荐系统">基于标签的推荐系统</h2>
<p>算法描述：<br>
1.统计每个用户最常用的标签。<br>
2.对于每个标签，统计被打过这个标签次数最多的物品。<br>
3.对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。<br>
<img src="https://lushunn.github.io/post-images/1575556110325.png" alt=""><br>
算法的改进：<br>
1.TF-IDF<br>
前面这个公式倾向于给热门标签对应的热门物品很大的权重，因此会造成推荐热门的物品给<br>
用户，从而降低推荐结果的新颖性。<br>
<img src="https://lushunn.github.io/post-images/1575556521824.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575556549020.png" alt=""><br>
2.数据的稀疏性<br>
在前面的算法中，用户兴趣和物品的联系是通过<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>⋂</mo><mi>B</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">B(u)\bigcap B(i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">⋂</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span>中的标签建立的。但是，对于新<br>
用户或者新物品，这个集合<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>⋂</mo><mi>B</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">B(u)\bigcap B(i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">⋂</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mopen">(</span><span class="mord mathdefault">i</span><span class="mclose">)</span></span></span></span>中的标签数量会很少。<br>
解决方法：进行标签扩展，找到相似的标签。<br>
<img src="https://lushunn.github.io/post-images/1575556826981.png" alt=""><br>
3.标签清理<br>
1)去除词频很高的停止词；<br>
2)去除因词根不同造成的同义词，比如 recommender system和recommendation system；<br>
3)去除因分隔符造成的同义词，比如 collaborative_filtering和collaborative-filtering 为了控制标签的质量，很多网站也采用了让用户进行反馈的思想，即让用户告诉系统某个标签是否合适。</p>
<h2 id="基于图的推荐算法">基于图的推荐算法</h2>
<p>我们需要定义3种不同的顶点，即用户顶点、物品顶点和标签顶点.表示用户u给物品i打了标签b的用户标签行为(u,i,b)，在定义出用户—物品—标签图后，我们可以用第2章提到的PersonalRank算法计算所有物品节点相对于当前用户节点在图上的相关性，然后按照相关性从大到小的排序，给用户推荐排名最高的N个物品。<br>
<img src="https://lushunn.github.io/post-images/1575646440140.png" alt=""></p>
<h2 id="用图模型解释前面的简单算法">用图模型解释前面的简单算法</h2>
<figure data-type="image" tabindex="1"><img src="https://lushunn.github.io/post-images/1575647430788.png" alt=""></figure>
<h2 id="给用户推荐标签">给用户推荐标签</h2>
<p>如何给用户推荐标签</p>
<ul>
<li>给用户u推荐整个系统里最热门的标签</li>
<li>给用户u推荐物品i上最热门的标签</li>
<li>给用户u推荐他自己经常使用的标签</li>
<li>前面两种的融合（这里记为HybridPopularTags），该方法通过一个系数将上面的推荐结果线性加权，然后生成最终的推荐结果。（在将两个列表线性相加时都将两个列表按最大值做了归一化，这样的好处是便于控制两个列表对最终结果的影响，而不至于因为物品非常热门而淹没用户对推荐结果的影响，或者因为用户非常活跃而淹没物品对推荐结果的影响。）</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《推荐系统实践》读书笔记 第1-2章]]></title>
        <id>https://lushunn.github.io/post/wa-keng-tui-jian-xi-tong-start</id>
        <link href="https://lushunn.github.io/post/wa-keng-tui-jian-xi-tong-start">
        </link>
        <updated>2019-12-04T14:51:06.000Z</updated>
        <content type="html"><![CDATA[<h1 id="目录">目录</h1>
<!-- TOC -->
<ul>
<li><a href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%A5%BD%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F">第一章 好的推荐系统</a>
<ul>
<li><a href="#1%E4%BB%80%E4%B9%88%E6%98%AF%E5%A5%BD%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F">1.什么是好的推荐系统</a></li>
<li><a href="#2%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E9%AA%8C%E6%96%B9%E6%B3%95">2.推荐系统实验方法</a></li>
<li><a href="#3%E8%AF%84%E6%B5%8B%E6%8C%87%E6%A0%87">3.评测指标</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0%E5%88%A9%E7%94%A8%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE">第二章利用用户行为数据</a>
<ul>
<li><a href="#1%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90">1.用户行为分析</a></li>
<li><a href="#2%E5%9F%BA%E4%BA%8E%E9%82%BB%E5%9F%9F%E7%9A%84%E7%AE%97%E6%B3%95">2.基于邻域的算法</a>
<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95">基于用户的协同过滤算法</a></li>
<li><a href="#%E7%94%A8%E6%88%B7%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E7%9A%84%E6%94%B9%E8%BF%9B">用户相似度计算的改进</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95">基于物品的协同过滤算法</a></li>
<li><a href="#%E7%94%A8%E6%88%B7%E6%B4%BB%E8%B7%83%E5%BA%A6%E5%AF%B9%E7%89%A9%E5%93%81%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%9A%84%E5%BD%B1%E5%93%8D">用户活跃度对物品相似度的影响</a></li>
<li><a href="#%E7%89%A9%E5%93%81%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%9A%84%E5%BD%92%E4%B8%80%E5%8C%96">物品相似度的归一化</a></li>
<li><a href="#usercf%E5%92%8Citemcf%E7%9A%84%E7%BB%BC%E5%90%88%E6%AF%94%E8%BE%83">UserCF和ItemCF的综合比较</a></li>
<li><a href="#%E9%9A%90%E8%AF%AD%E4%B9%89%E6%A8%A1%E5%9E%8B">隐语义模型</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8Elfm%E7%9A%84%E5%AE%9E%E9%99%85%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BE%8B%E5%AD%90">基于LFM的实际系统的例子</a></li>
<li><a href="#lfm%E5%92%8C%E5%9F%BA%E4%BA%8E%E9%A2%86%E5%9F%9F%E7%9A%84%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83">LFM和基于领域的方法的比较</a></li>
</ul>
</li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E6%A8%A1%E5%9E%8B">3.基于图的模型</a>
<ul>
<li><a href="#1%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E7%9A%84%E4%BA%8C%E5%88%86%E5%9B%BE%E8%A1%A8%E7%A4%BA">用户行为数据的二分图表示</a></li>
<li><a href="#2%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95">基于图的推荐算法</a><!-- /TOC --></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h1 id="第一章-好的推荐系统">第一章 好的推荐系统</h1>
<h2 id="1什么是好的推荐系统">1.什么是好的推荐系统</h2>
<p>好的推荐系统能使用户、物品提供者和提供推荐系统的平台三方达到共赢。<br>
<img src="https://lushunn.github.io/post-images/1575381642094.png" alt=""></p>
<h2 id="2推荐系统实验方法">2.推荐系统实验方法</h2>
<p>在推荐系统中，主要有3种评测推荐效果的实验方法，即离线实验（offline experiment）、用户调（user study）和在线实验（online experiment）。</p>
<ul>
<li>
<p>离线实验<br>
(1) 通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集；<br>
(2) 将数据集按照一定的规则分成训练集和测试集；<br>
(3) 在训练集上训练用户兴趣模型，在测试集上进行预测；<br>
<img src="https://lushunn.github.io/post-images/1575382135010.png" alt=""></p>
</li>
<li>
<p>用户调查</p>
</li>
<li>
<p>在线实验<br>
下图是一个简单的AB测试系统。用户进入网站后，流量分配系统决定用户是否需要被进<br>
行AB测试，如果需要的话，流量分配系统会给用户打上在测试中属于什么分组的标签。然后用<br>
户浏览网页，而用户在浏览网页时的行为都会被通过日志系统发回后台的日志数据库。此时，如<br>
果用户有测试分组的标签，那么该标签也会被发回后台数据库。在后台，实验人员的工作首先是<br>
配置流量分配系统，决定满足什么条件的用户参加什么样的测试。其次，实验人员需要统计日志<br>
数据库中的数据，通过评测系统生成不同分组用户的实验报告，并比较和评测实验结果。<br>
<img src="https://lushunn.github.io/post-images/1575382258504.png" alt=""><br>
一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验。<br>
1)首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。<br>
2)然后，需要通过用户调查确定它的用户满意度不低于现有的算法。<br>
3)最后，通过在线的AB测试确定它在我们关心的指标上优于现有的算法。</p>
</li>
</ul>
<h3 id="3评测指标">3.评测指标</h3>
<p>1)用户满意度<br>
2)预测准确度</p>
<ul>
<li>评分预测<br>
<img src="https://lushunn.github.io/post-images/1575382587613.png" alt=""></li>
<li>TopN推荐<br>
<img src="https://lushunn.github.io/post-images/1575382664978.png" alt=""></li>
<li>覆盖率<br>
覆盖率（coverage）描述一个推荐系统对物品长尾的发掘能力。覆盖率有不同的定义方法，最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。假设系统的用户集合为U，推荐系统给每个用户推荐一个长度为N的物品列表R(u)<br>
<img src="https://lushunn.github.io/post-images/1575382755052.png" alt=""><br>
覆盖率是一个内容提供商会关心的指标，上面的定义过于粗略。覆盖率为100%的系统可以有无数的物品流行度分布。为了更细致地描述推荐系统发掘长尾的能力，需要统计推荐列表中不同物品出现次数的分布。如果所有的物品都出现在推荐列表中，且出现的次数差不多，那么推荐系统发掘长尾的能力就很好。<br>
<img src="https://lushunn.github.io/post-images/1575383569449.png" alt=""></li>
<li>多样性<br>
<img src="https://lushunn.github.io/post-images/1575383639902.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575383644382.png" alt=""></li>
<li>新颖度</li>
<li>惊喜度</li>
<li>信任度</li>
<li>实时性<br>
（1）推荐系统需要实时地更新推荐列表来满足用户新的行为变化。<br>
（2）推荐系统需要能够将新加入系统的物品推荐给用户。</li>
<li>健壮性</li>
</ul>
<p>#第二章利用用户行为数据<br>
基于用户行为分析的推荐算法是个性化推荐系统的重要算法，学术界一般将这种类型的算法<br>
称为协同过滤算法。</p>
<p>用户行为在个性化推荐系统中一般分两种——显性反馈行为（explicit feedback）和隐性反馈<br>
行为（implicit feedback）。显性反馈行为包括用户明确表示对物品喜好的行为。隐性反馈行为指的是那些不能明确反应用户喜好的行为。最具代表性的隐性反馈行为就是页面浏览行为。<br>
<img src="https://lushunn.github.io/post-images/1575384226268.png" alt=""><br>
<img src="https://lushunn.github.io/post-images/1575384235006.png" alt=""></p>
<h2 id="1用户行为分析">1.用户行为分析</h2>
<p>很多关于互联网数据的研究发现，互联网上的很多数据分布都满足一种称为Power Law的分布，这个分布在互联网领域也称长尾分布。</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><msup><mi>x</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">f(x)=ax^k 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8991079999999999em;vertical-align:0em;"></span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>（1）不管是物品的流行度还是用户的活跃度，都近似于长尾分布。<br>
（2）用户越活跃，越倾向于浏览冷门的物品</p>
<h2 id="2基于邻域的算法">2.基于邻域的算法</h2>
<h3 id="基于用户的协同过滤算法">基于用户的协同过滤算法</h3>
<p>基于用户的协同过滤算法主要包括两个步骤。<br>
(1) 找到和目标用户兴趣相似的用户集合。<br>
<img src="https://lushunn.github.io/post-images/1575385068600.png" alt=""><br>
直接对两两用户都利用余弦相似度计算相似度算法时间复杂度较大，用户数很大时非常耗时。<br>
改进1:</p>
<p>思路：我们可以首先计算出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>∣</mo><mi>N</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>⋂</mo><mi>N</mi><mo>(</mo><mi>v</mi><mo>)</mo><mo>∣</mo><mpadded width="0px"><mo></mo></mpadded><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\mid N(u) \bigcap N(v)\mid \not=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">⋂</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> 的用户对(u,v)，然后再对这种情况除以分母<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msqrt><mrow><mo>∣</mo><mi>N</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>⋂</mo><mi>N</mi><mo>(</mo><mi>v</mi><mo>)</mo><mo>∣</mo></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{\mid N(u) \bigcap N(v) \mid}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.24em;vertical-align:-0.30500499999999997em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.934995em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">⋂</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span></span></span><span style="top:-2.894995em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,
158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067
c4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,
175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71
c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,
-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26
s76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.30500499999999997em;"><span></span></span></span></span></span></span></span></span>。<br>
具体实现：<br>
为此，可以首先建立物品到用户的倒排表，对于每个物品都保存对该物品产生过行为的用户<br>
列表。令稀疏矩阵<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>[</mo><mi>u</mi><mo>]</mo><mo>[</mo><mi>v</mi><mo>]</mo><mo>=</mo><mo>∣</mo><mi>N</mi><mo>(</mo><mi>u</mi><mo>)</mo><mo>⋂</mo><mi>N</mi><mo>(</mo><mi>v</mi><mo>)</mo><mo>∣</mo></mrow><annotation encoding="application/x-tex">C[u][v]=\mid N(u)\bigcap N(v)\mid</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathdefault">u</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.00001em;vertical-align:-0.25001em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">⋂</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span></span></span></span>。那么，假设用户u和用户v同时属于倒排表中K个物品对应的用户列表，就有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>[</mo><mi>u</mi><mo>]</mo><mo>[</mo><mi>v</mi><mo>]</mo><mo>=</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">C[u][v]=K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathdefault">u</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span>。从而，可以扫描倒排表中每个物品对应的用户列表，将用户列<br>
表中的两两用户对应的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>[</mo><mi>u</mi><mo>]</mo><mo>[</mo><mi>v</mi><mo>]</mo></mrow><annotation encoding="application/x-tex">C[u][v]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathdefault">u</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">]</span></span></span></span>加1，最终就可以得到所有用户之间不为0的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>[</mo><mi>u</mi><mo>]</mo><mo>[</mo><mi>v</mi><mo>]</mo></mrow><annotation encoding="application/x-tex">C[u][v]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mopen">[</span><span class="mord mathdefault">u</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">]</span></span></span></span>。<br>
倒排表的生成（物品:a,b,c,d 用户:A,B,C,D）<br>
<img src="https://lushunn.github.io/post-images/1575471780624.png" alt=""></p>
<p>(2) 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。<br>
<img src="https://lushunn.github.io/post-images/1575471908075.png" alt=""></p>
<h3 id="用户相似度计算的改进">用户相似度计算的改进</h3>
<figure data-type="image" tabindex="1"><img src="https://lushunn.github.io/post-images/1575472013099.png" alt=""></figure>
<h3 id="基于物品的协同过滤算法">基于物品的协同过滤算法</h3>
<p>需求：随着网站的用户数目越来越大，计算用户兴趣相似度矩阵将越来越困难，其运算时间复杂度和空<br>
间复杂度的增长和用户数的增长近似于平方关系。<br>
基于物品的协同过滤算法主要分为两步。<br>
(1) 计算物品之间的相似度。<br>
<img src="https://lushunn.github.io/post-images/1575472496337.png" alt=""></p>
<p><img src="https://lushunn.github.io/post-images/1575472555034.png" alt=""><br>
(2) 根据物品的相似度和用户的历史行为给用户生成推荐列表。<br>
<img src="https://lushunn.github.io/post-images/1575472653595.png" alt=""></p>
<h3 id="用户活跃度对物品相似度的影响">用户活跃度对物品相似度的影响</h3>
<figure data-type="image" tabindex="2"><img src="https://lushunn.github.io/post-images/1575472771304.png" alt=""></figure>
<h3 id="物品相似度的归一化">物品相似度的归一化</h3>
<p>将ItemCF的相似度矩阵按最大值归一化，好处不仅仅在于增加推荐的准确度，它还可以提高推荐的覆盖率和多样性。</p>
<h3 id="usercf和itemcf的综合比较">UserCF和ItemCF的综合比较</h3>
<figure data-type="image" tabindex="3"><img src="https://lushunn.github.io/post-images/1575472925837.png" alt=""></figure>
<ul>
<li>哈利波特问题<br>
<img src="https://lushunn.github.io/post-images/1575473550336.png" alt=""></li>
</ul>
<h3 id="隐语义模型">隐语义模型</h3>
<p>UserCF：首先需要找到和他们看了同样书的其他用户（兴趣相似的用户），然后给他<br>
们推荐那些用户喜欢的其他书。<br>
ItemCF：需要给他们推荐和他们已经看的书相似的书，比如作者B看了很多关于数据<br>
挖掘的书，可以给他推荐机器学习或者模式识别方面的书。<br>
新的算法思路：可以对书和物品的兴趣进行分类。对于某个用户，首先得到他的兴趣分类，<br>
然后从分类中挑选他可能喜欢的物品。隐含语义分析技术，因为采取基于用户行为统计的自动聚类，较好的满足了新的算法思路所带来的问题。<br>
<img src="https://lushunn.github.io/post-images/1575473764530.png" alt=""><br>
如何解决隐性反馈数据集上应用LFM解决TopN推荐的没有负样本这个问题：<br>
1.对于一个用户，从他没有过行为的物品中均匀采样出一些物品作为负样本。</p>
<ol>
<li>对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证<br>
每个用户的正负样本数目相当。<br>
3.对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，偏重<br>
采样不热门的物品。<br>
通过2011年的KDD Cup的Yahoo! Music推荐系统比赛的采样方案<br>
1.对每个用户，要保证正负样本的平衡（数目相似）。<br>
2.对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。</li>
</ol>
<h3 id="基于lfm的实际系统的例子">基于LFM的实际系统的例子</h3>
<figure data-type="image" tabindex="4"><img src="https://lushunn.github.io/post-images/1575474097153.png" alt=""></figure>
<p>遇到的困难：经典的LFM模型每次训练时都需要扫描所有的用户行为记录，这样才能计算出用户隐类向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><msub><mi>p</mi><mi>u</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">(p_u)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>和物品隐类向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><msub><mi>q</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">(q_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。LFM的每次训练都很耗时，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。从而LFM模型不能因为用户行为的变化实时地调整推荐结果来满足用户最近的行为。在新闻推荐中，冷启动问题非常明显。每天都会有大量新的新闻。这些新闻会在很短的时间内获得很多人的关注，但也会在很短的时间内失去用户的关注。因此，它们的生命周期很短，而推荐算法需要在它们短暂的生命周期内就将其推荐给对它们感兴趣的用户。<br>
解决方法：<br>
<img src="https://lushunn.github.io/post-images/1575474302058.png" alt=""></p>
<h3 id="lfm和基于领域的方法的比较">LFM和基于领域的方法的比较</h3>
<p>1)理论基础：LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标建立最优的模型。基于邻域的方法更多的是一种基于统计的方法，并没有学习过程。<br>
2)离线计算的空间复杂度：基于邻域的方法需要维护一张离线的相关表。在离线计算相关表的过程中，如果用户/物品数很多，将会占据很大的内存。LFM只需占用很少的内存。<br>
3)离线计算的时间复杂度：总体上来说两者没有太大差别。<br>
4)在线实时推荐：UserCF和ItemCF在线服务算法需要将相关表缓存在内存中，然后可以在线进行实时的预测。LFM在给用户生成推荐列表时，需要计算用户对所有物品的兴趣权重，然后排名，返回权重最大的N个物品。那么，在物品数很多时，这一过程的时间复杂度非常高，LFM不太适合用于物品数非常庞大的系统，也不能实时计算。<br>
5)推荐解释：ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。但LFM无法提供这样的解释。</p>
<h3 id="基于图的模型">基于图的模型</h3>
<h4 id="1用户行为数据的二分图表示">1.用户行为数据的二分图表示</h4>
<p>基于图的模型（graph-based model）是推荐系统中的重要内容。用户行为数据是由一系列二元组组成的，其中每个二元组(u, i)表示用户u对物品i产生过行为。这种数据集很容易用一个二分图表示。(用户节点A,B,C和物品节点a、b、c,d)<br>
<img src="https://lushunn.github.io/post-images/1575474753472.png" alt=""></p>
<h4 id="2基于图的推荐算法">2.基于图的推荐算法</h4>
<p>基于上一步，下面的任务就是在二分图上给用户进行个性化推荐。那么给用户u推荐物品的任务就可以转化为度量用户顶点<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>u</mi></msub></mrow><annotation encoding="application/x-tex">v_u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和与<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>v</mi><mi>u</mi></msub></mrow><annotation encoding="application/x-tex">v_u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>没有边直接相连的物品节点在图上的相关性，相关性越高的物品在推荐列表中的权重就越高。<br>
<img src="https://lushunn.github.io/post-images/1575475124113.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ C++ wk1学习笔记 面向对象程序设计]]></title>
        <id>https://lushunn.github.io/post/c-wk1-xue-xi-bi-ji-mian-xiang-dui-xiang-cheng-xu-she-ji</id>
        <link href="https://lushunn.github.io/post/c-wk1-xue-xi-bi-ji-mian-xiang-dui-xiang-cheng-xu-she-ji">
        </link>
        <updated>2019-10-09T12:34:59.000Z</updated>
        <content type="html"><![CDATA[<h1 id="c-wk1学习笔记-面向对象程序设计">C++ wk1学习笔记 面向对象程序设计</h1>
<p>参考资料</p>
<p><a href="https://www.coursera.org/learn/cpp-chengxu-sheji/home/welcome">C++程序设计 北京大学郭炜</a></p>
<p><a href="https://blog.csdn.net/tianxiaolu1175/article/details/46889523">(https://blog.csdn.net/tianxiaolu1175/article/details/46889523)</a></p>
<h2 id="1引用">1.引用</h2>
<h3 id="引用的概念">引用的概念</h3>
<p>引用（reference）： 引用只是别名，不是实体类型（也就是说c++编译器不为引用单独分配内存空间），对一个对象的引用，就是直接对这个对象的操作。</p>
<p>下面的写法定义了一个引用，并将其初始化为引用某个变量。</p>
<blockquote>
<p>类型名  &amp; 引用名=某变量名；</p>
</blockquote>
<pre><code class="language-C++">
int n = 4；  
int &amp; r = n; //r引用了n,r的类型是 int &amp;

</code></pre>
<p>示例1:</p>
<pre><code class="language-C++">int n = 4;
int &amp; r = n;
r = 4;
cout &lt;&lt; r; //输出 4
cout &lt;&lt; n; //输出 4    
n = 5;
cout &lt;&lt; r; //输出 5
</code></pre>
<p>三个特性：</p>
<p>1.定义引用时一定要将其初始化成引用某个变量。</p>
<p>2.初始化后，它就一直在引用该变量，不会再引用其他别的变量了。</p>
<p>3.引用只能引用变量，不能引用常量和表达式。</p>
<p>示例2：</p>
<pre><code class="language-C++">double a=4;b=5
double &amp; r1=a;//引用必须初始化,不可以更改其指向的目标
double &amp; r2=r1;//r2也引用a
r2 = 10;
cout&lt;&lt;a&lt;&lt;endl;// &gt;&gt;10
r1 = b;//这里只是把b的值赋给r1也就是a,
//而并不是使引用的目标由对a的引用到对b的引用 
cout&lt;&lt;a&lt;&lt;endl;//&gt;&gt;5
</code></pre>
<h3 id="引用的具体使用场景">引用的具体使用场景</h3>
<ol>
<li>引用型参数</li>
</ol>
<p>使用引用型参数有两个好处：（1）因为函数形参和实参是同一个对象，也就不存在对象复制，避免了对象的开销。（2）可以在修改形参的同时对实参的修改。当然了，为了避免函数对原来实参的意外修改我们可以 用const 对引用加以修饰 也就是传常引用。传常引用有两个优势（1）因为不存在拷贝构造所以，可以提高c++程序的执行效率（2）避免对象切割问题。</p>
<ol start="2">
<li>引用型返回值</li>
</ol>
<p>从函数中返回引用，一定要保证在函数返回以后，被引用的目标一直有效，也就是不能返回函数体内的局部对象的引用，大家都知道， 局部对象离开作用域就会被析构掉，所以不能返回对函数体内的局部对象的引用。</p>
<p>示例3：</p>
<pre><code class="language-C++">void swap(int &amp;a, int &amp;b)
{

    int tmp;
    tmp=a;a=b;b=tmp;
}
int n1,n2;
swap(n1,n2);//交换a,b的值

</code></pre>
<p>示例4：</p>
<pre><code class="language-C++">int n=4;
int &amp;SetValue() {return n;}
int main()
{
    SetValue()=40;
    count&lt;&lt;n;//print 40
    return 0;
}

</code></pre>
<h3 id="常引用">常引用</h3>
<p>定义引用时，前面加const关键字，即为“常引用”</p>
<pre><code class="language-C++">int n;
const int  &amp; r=n;
</code></pre>
<p>r的类型是 const int&amp;；</p>
<p>特性：不能通过常引用去修改其引用的内容</p>
<p>示例5：</p>
<pre><code class="language-C++">int n =100;

const int &amp; r=n;
r=200;//编译时出错
n=300;//ok

</code></pre>
<p>cont T &amp; 和 T &amp;是不同的类型。</p>
<p>T &amp;类型的引用或T类型的变量可以用来初始化 const T &amp;类型的引用。</p>
<p>const T类型的常变量和const T &amp;类型的引用则不能用来初始化T &amp;类型的引用，除非进行强制类型转换。</p>
<h4 id="const关键字的用法">const关键字的用法</h4>
<ol>
<li>定义常量</li>
</ol>
<pre><code class="language-C++">    const int MAX_LEN=23;
</code></pre>
<ol start="2">
<li>定义常量指针</li>
</ol>
<p>不可以通过常量指针修改其指向的内容</p>
<pre><code class="language-C++">int n,m;
const int *p=&amp;n;
*p=5;//编译时出错
n=4;//ok
p=&amp;m; //ok,指针方向可以变化
</code></pre>
<p>不能把常量指针赋值给非常量指针，反之可行</p>
<pre><code class="language-C++">const int *p1;int *p2;
p1=p2; //ok
p2=p1;//编译时出错
p2=(int *) p1; //强制类型转换后ok
</code></pre>
<p>函数参数为常量指针时，可避免函数内部不小心改变参数指针所指地方的内容。</p>
<ol start="3">
<li>不能通过常引用修改其引用的变量</li>
</ol>
<h2 id="2-动态内存分配">2. 动态内存分配</h2>
<p>分配变量：</p>
<pre><code class="language-C++">    P= new T;
</code></pre>
<p>T是任意类型名，P是类型为T *的指针。<br>
动态分配出一片大小为sizeof(T)字节的内存空间，并且将该内存空间的起始地址赋值给P。比如</p>
<pre><code class="language-C++">int* pn;
pn= new int;
* pn= 5;
</code></pre>
<p>分配数组：</p>
<pre><code class="language-C++">   P = new T[N];
</code></pre>
<p>T :任意类型名</p>
<p>P :类型为T *的指针</p>
<p>N :要分配的数组元素的个数，可以是整型表达式</p>
<p>动态分配出一片大小为sizeof(T)字节的内存空间，并且将该内存空间的起始地址赋值给P。<br>
动态分配数组示例：</p>
<pre><code class="language-c++">int* pn;
inti= 5;
pn= new int[i* 20];

</code></pre>
<p>用“new”动态分配的内存空间，一定要用“delete”运算符进行释放</p>
<pre><code class="language-c++">delete 指针；//该指针必须指向new出来的空间
</code></pre>
<h2 id="3-内联函数-函数重载-函数缺省参数">3. 内联函数 函数重载 函数缺省参数</h2>
<h3 id="内联函数">内联函数</h3>
<p>函数调用是有时间开销的。如果函数本身只有几条语句，执行非常快，而且函数被反复执行很多次，相比之下调用函数所产生的这个开销就会显得比较大。</p>
<p>为了减少函数调用的开销，引入了内联函数机制。编译器处理对内联函数的调用语句时，是将整个函数的代码插入到调用语句处，而不会产生调用函数的语句。</p>
<pre><code class="language-c++">inline intMax(inta,intb)
{
if( a &gt; b) return a;
return b;
}
</code></pre>
<h3 id="函数重载">函数重载</h3>
<p>一个或多个函数，名字相同，然而参数个数或参数类型不相同，这叫做函数的重载</p>
<ul>
<li>以下三个函数是重载关系：</li>
</ul>
<pre><code class="language-c++">intMax(double f1,double f2) { }

intMax(intn1,int n2) { }

intMax(intn1,int n2,int n3) { }
</code></pre>
<ul>
<li>函数重载使得函数命名变得简单。</li>
<li>编译器根据调用语句的中的实参的个数和类型判断应该调用哪个函数。</li>
</ul>
<h3 id="缺省函数">缺省函数</h3>
<p>C++中，定义函数的时候可以让最右边的连续若干个参数有缺省值，那么调用函数的时候，若相应位置不写参数，参数就是缺省值。</p>
<pre><code class="language-c++">void func( intx1, intx2 = 2, intx3= 3) { }
func(10 ) ; //等效于func(10,2,3)
func(10,8) ; //等效于func(10,8,3)
</code></pre>
<h2 id="4类">4.类</h2>
<pre><code class="language-c++">class CRectangle {
    public:
    int w, h;
    void Init( int w_, int h_ ) {
        w = w_; h = h_;
    }
    int Area() {
        return w * h;
    }
    int Perimeter() {
        return 2 * ( w + h );
    }
}; //必须有分号
int main() {
    int w, h;
    CRectangle r; //r是一个对象
    cin &gt;&gt; w &gt;&gt; h;
    r.Init(w, h);
    cout &lt;&lt; r.Area() &lt;&lt; endl &lt;&lt; r. Perimeter();
    return 0;   
}

</code></pre>
<p>类定义的变量-&gt;类的实例-&gt;“对象”</p>
<h3 id="对象的内存分配">对象的内存分配</h3>
<p>对象的内存空间</p>
<p>•对象的大小 = 所有成员变量的大小之和</p>
<p>•E.g. CRectangle类的对象, sizeof(CRectangle) = 8</p>
<p>每个对象各有自己的存储空间</p>
<p>•一个对象的某个成员变量被改变, 不会影响到其他的对象</p>
<h3 id="访问类的成员变量和成员函数">访问类的成员变量和成员函数</h3>
<p>用法1: 对象名.成员名</p>
<pre><code class="language-c++">    CRectangle r1, r2;
    r1.w = 5;
    r2.Init(3,4);
</code></pre>
<p>用法2: 指针-&gt;成员名</p>
<pre><code class="language-c++">CRectangle r1, r2;
CRectangle * p1 = &amp; r1;
CRectangle * p2 = &amp; r2;
p1-&gt;w = 5;
p2-&gt;Init(3,4); //Init作用在p2指向的对象上
</code></pre>
<p>用法3: 引用名.成员名</p>
<pre><code class="language-c++">CRectangle r2;
CRectangle &amp; rr = r2;
rr.w = 5;
rr.Init(3,4); //rr的值变了，r2的值也变
</code></pre>
<h3 id="类的成员函数的另一种写法">类的成员函数的另一种写法</h3>
<pre><code class="language-c++">int CRectangle::Area() {
return w * h;
}
int CRectangle::Perimeter() {
return 2 * ( w + h );
}
void CRectangle::Init( int w_, int h_ ) {
w = w_; h = h_;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[挖坑 C++备忘录]]></title>
        <id>https://lushunn.github.io/post/wa-keng-ctc</id>
        <link href="https://lushunn.github.io/post/wa-keng-ctc">
        </link>
        <updated>2019-09-28T02:13:23.000Z</updated>
        <content type="html"><![CDATA[<p>待写</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[无监督学习Neighbor Embedding近邻嵌入--从LLE 到 T-SNE ]]></title>
        <id>https://lushunn.github.io/post/wa-keng-t-sne</id>
        <link href="https://lushunn.github.io/post/wa-keng-t-sne">
        </link>
        <updated>2019-09-28T02:12:36.000Z</updated>
        <content type="html"><![CDATA[<p>参考资料:<a href="https://www.bilibili.com/video/av9770190/?p=15">李宏毅机器学习(2016)</a>；</p>
<p>Neighbor Embedding近邻嵌入不同于PCA，实际上是一种非线性的降维方法，本文对三种常用的近邻嵌入算法做简单的介绍。</p>
<p><strong>概念：流式学习(Manifold Learning)</strong></p>
<p>流式学习的目的抽象的来说就是寻找高维空间的低维规律，即样本点的分布其实可能是在低维的一个空间里，只是被扭曲被塞到高维空间里面。最常用的举例就是地球，地球的表面就是一个manifold(一个二维的平面，被塞到一个三维的空间里面)。在manifold里面只有很近距离的点，（欧式距离）Euclidean distance才会成立，如果距离很远的时候，欧式距离不一定成立。如在图中，a点计算离d,e两点的欧式距离都很近，这符合我们的直觉，但是同样根据欧式距离，a点距离b点比距离c点更近，但事实上如果我们把“S”形的数据点分布摊平展开，可能直觉上a点距离b点比a点距离点更加远。<br>
所以流式计算要做的事情是把类似于图中“S”型的高维分布在低维度空间进行展开。展开的好处就是：把这个塞到高维空间里的manifold摊平以后，我们就可以在这个manifold上面用Euclidean distance来计算样本之间的距离，这会对接下来你要做supervised learning都是有帮助。<br>
<img src="https://lushunn.github.io/post-images/1569643061791.png" alt=""></p>
<p>下面依次介绍几中近邻嵌入的降维方法。</p>
<h1 id="locally-linear-emeddinglle局部线性嵌入">Locally Linear Emedding(LLE)局部线性嵌入</h1>
<p><img src="https://lushunn.github.io/post-images/1569643722864.png" alt=""><br>
对于样本空间的任意一个样本点，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">x^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span>,存在k个neighbor叫做<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">x^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span>（“局部”），满足假设条件每一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">x^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span> 都可以用它的neighbor<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">x^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span>乘以关系权重<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>以后组合而成(“线性”)，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>可以通过优化算法，求解最小化以下公式求得，也就是对所有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">x^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span>减掉<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>乘以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">x^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span>求和的L2-Norm是越接近越好。<br>
<img src="https://lushunn.github.io/post-images/1569644549867.png" alt=""></p>
<p>最后一步也就是降维，基于以上计算求得的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>，在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>不变的前提的，通过优化算法，把原来的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">x^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">x^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span>统统转成维度更低的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>z</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">z^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>z</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">z^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span>。<br>
<img src="https://lushunn.github.io/post-images/1569645149334.png" alt=""></p>
<h1 id="拉普拉斯特征映射laplaciain-eigenmaps">拉普拉斯特征映射（Laplaciain Eigenmaps）</h1>
<h2 id="概念">概念</h2>
<ul>
<li>
<p>Smoothness Assumption<br>
<img src="https://lushunn.github.io/post-images/1569659502505.png" alt=""><br>
Smoothness Assumption的大概内容介绍如下图，简单的说就是如果x的分布是不平均的，它在某些地方是很集中，某些地方又很分散。如果<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>在高密度区域(high density region)距离很接近的话，他们的标签<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>y</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">y^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>y</mi><mn>2</mn></msup><mo separator="true">,</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">y^2,y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>才会是是很像的。(反面例子是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">x_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)</p>
</li>
<li>
<p>拉普拉斯矩阵(graph Laplacian)<br>
拉普拉斯矩阵（graph Laplacian)），也称为基尔霍夫矩阵, 是表示图的一种矩阵。给定一个有n个顶点的图G=（V，E） ，其拉普拉斯矩阵被定义为:L=D-W,其中D为图的度矩阵（各个顶点的度构成的对角矩阵），W为图的邻接矩阵（表示各个顶点相互连接关系的矩阵，取值为0，1）。</p>
</li>
</ul>
<p>拉普拉斯特征映射是用局部的角度去构建数据之间的关系。具体来讲，拉普拉斯特征映射是一种基于图的降维算法，它希望相互间有关系的点（在图中相连的点）在降维后的空间中尽可能的靠近，从而在降维后仍能保持原有的数据结构，即同样尽可能的靠近（Smoothness Assumption）。</p>
<p>拉普拉斯特征映射的目标函数，相当于有监督学习的unlabel data项，也就是正则项。S这一项等于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>y</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">y^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.019104em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span>跟<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>y</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">y^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.019104em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span> 之间的距离 乘以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{i,j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{i,j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>意思是如果两个顶点它们在图上是相连的，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{i,j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>是它们的相似程度；在图上没有相连就是0。如果<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">x^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span>跟<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">x^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span>接近的话，那<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{i,j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 就是一个很大的值。根据上面拉普拉斯矩阵的概念，这个S还可以写成<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mo>=</mo><msup><mi>y</mi><mi>T</mi></msup><mi>L</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">S=y^TLy</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>(L是graph laplacian，L=D-W)<br>
<img src="https://lushunn.github.io/post-images/1569661372666.png" alt=""><br>
同时，我们还需要施加一个限制条件，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>Y</mi><mi>T</mi></msup><mi>D</mi><mi>Y</mi><mo>=</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">Y^TDY=I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span></span></span></span>来保证问题有解，防止映射后的样本点被压缩到一个维度比m还小的空间中去（假设映射后的z向量的维度为m），比如下图的思考，在minimize S的时候，如果选择<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>z</mi><mi>i</mi></msup><mo>=</mo><msup><mi>z</mi><mi>j</mi></msup><mo>=</mo><mn>0</mn><mo separator="true">,</mo><mi>S</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">z^i=z^j=0,S=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>，优化过程会直接直接终止，这并不是我们想要的结果。</p>
<figure data-type="image" tabindex="1"><img src="https://lushunn.github.io/post-images/1569661806671.png" alt=""></figure>
<h1 id="t-分布随机领域t-sne">T-分布随机领域（t-SNE）</h1>
<p><img src="https://lushunn.github.io/post-images/1569662292819.png" alt=""><br>
前述算法中，求解优化思路都是假设映射前后的相邻点都要尽可能接近，而不是不相似的点尽可能分开，这样就会导致一个降维中经常出现的问题，即拥挤问题（Crowding Problem）。如上图，LLE在MNIST上会遇到这样的情形：它确实会把同一个class聚集在一起，但它没有防止不同class的点不要叠成一团。</p>
<figure data-type="image" tabindex="2"><img src="https://lushunn.github.io/post-images/1569662474432.png" alt=""></figure>
<p>t-SNE的降维其实和上述算法仍然类似，把原来的样本点映射成低维向量z。在原来的空样本间上面，我们会计算所有样本对的相似度（同样的计算过程应用在低维向量z的样本空间中）。上图中P和Q的计算实际上是在做了一个normlization，通过scale转化，值会介于0-1之间。</p>
<p>那怎么衡量两个空间分布之间的相似度呢？就是KL距离。所以我们要做的事情就是找一组z，它可以做到，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">x^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span>的样本分布跟<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>z</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">z^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span>样本分布的KL距离越小越好，然后汇总相加所有的样本点，使得上图中的L越小越好。</p>
<p>t-SNE的计算过程，会涉及到计算所有点的similarity，所以它的运算有点大。在样本量比较多的时候，t-SNE比较麻烦。第一个常见的做法是：你会先做降维，比如说：你原来的维度很大，你不会直接从很高的维度直接做t-SNE，因为你这样计算similarity时间会很长，你通常会先用PCA做将降维，降到50维，再用t-SNE降到2维，这个是比较常见的做法。</p>
<p>如果给t-SNE一个训练数据中没有新的样本点，没办法做到直接降维。t-SNE只能够你先给它一大群x，帮你把每个x的z先找出来，但你找完这些z以后，你再给它一个新的x，你要重新跑一遍这一整套演算法，所以就很麻烦。通常的应用场景是，有一大堆的高维度x的样本点，你想要知道它在二维空间的分布是什么样子，用t-SNE进行可视化，往往会有不错的效果。<br>
<img src="https://lushunn.github.io/post-images/1569664172988.png" alt=""><br>
t-SNE算法的核心在于相似度计算上的创新，在原来的样本点空间上面，计算相似度是计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">x^i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mi>j</mi></msup></mrow><annotation encoding="application/x-tex">x^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.824664em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span></span></span></span>之间的欧式距离，取一个负号，再取exponent，这种方法比较好，因为它可以确保说只有非常相近的点才有值，只要距离一拉开，similarity就会变得很小。 在t-SNE之前，有一个方法叫做SNE：对于降维以后向量z，它选择测量方式跟原来的样本是一样的。t-SNE神妙的地方在：降维以后的空间中，它选择的测量方式跟原来的样本空间是不一样的，它选择是t distribution变换的其中一种<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><msup><mi>S</mi><msup><mrow></mrow><mo mathvariant="normal">′</mo></msup></msup><mo>(</mo><msup><mi>z</mi><mi>i</mi></msup><mo separator="true">,</mo><msup><mi>z</mi><mi>j</mi></msup><mo>)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msup><mi>z</mi><mi>i</mi></msup><mo>−</mo><msup><mi>z</mi><mi>j</mi></msup><mi mathvariant="normal">∣</mi><msub><mi mathvariant="normal">∣</mi><mn>2</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">(S^{&#x27;}(z^i,z^j)=\frac{1}{1+||z^i-z^j||_2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.19248em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.94248em;"><span style="top:-2.94248em;margin-right:0.05em;"><span class="pstrut" style="height:2.57948em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278285714285715em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.365108em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight">∣</span><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857143em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7570857142857144em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mtight">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31731428571428577em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>,做完变换过后，原本样本空间中距离相差较大的样本点，在低维度空间中，会被拉得更大。从下图使用t-SNE算法做的降维可视化中就可以看出。</p>
<figure data-type="image" tabindex="3"><img src="https://lushunn.github.io/post-images/1569664038016.png" alt=""></figure>
]]></content>
    </entry>
</feed>